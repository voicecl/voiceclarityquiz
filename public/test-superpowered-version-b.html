<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Superpowered Version B Processing Test</title>
  <style>
    body { font-family: Arial, sans-serif; background: #f5f5f5; margin: 0; padding: 0; }
    .container { max-width: 700px; margin: 40px auto; background: #fff; border-radius: 10px; box-shadow: 0 2px 8px #0001; padding: 32px; }
    h1 { font-size: 2rem; margin-bottom: 0.5em; }
    .desc { color: #444; margin-bottom: 1.5em; }
    .log { background: #f8f9fa; border: 1px solid #dee2e6; border-radius: 4px; padding: 10px; margin: 10px 0; max-height: 200px; overflow-y: auto; font-family: monospace; font-size: 13px; }
    .audio-controls { margin: 1em 0; display: flex; gap: 1em; }
    .audio-controls audio { outline: 1px solid #ccc; border-radius: 4px; }
    .btn { background: #007bff; color: #fff; border: none; padding: 10px 18px; border-radius: 4px; cursor: pointer; font-size: 1rem; }
    .btn:disabled { background: #aaa; cursor: not-allowed; }
    .status { margin: 1em 0; padding: 0.7em 1em; border-radius: 4px; font-weight: bold; }
    .success { background: #d4edda; color: #155724; }
    .error { background: #f8d7da; color: #721c24; }
    .info { background: #d1ecf1; color: #0c5460; }
    .warning { background: #fff3cd; color: #856404; }
    label { font-weight: bold; }
  </style>
</head>
<body>
  <div class="container">
    <h1>Superpowered Version B Processing Test</h1>
    <div class="desc">
      <p><b>Goal:</b> Hear the effect of Version B (Light Internal Simulation) on your voice or a sample recording.</p>
      <ul>
        <li>Pitch shift: <b>-50 cents</b></li>
        <li>Formant correction: <b>0.95</b></li>
        <li>EQ: <b>+2dB at 300Hz</b> (warmth boost)</li>
      </ul>
      <p>Load a short WAV/MP3 file, process it, and compare the original and processed versions.</p>
    </div>
    <div>
      <label for="audio-file">Select audio file (WAV/MP3):</label>
      <input type="file" id="audio-file" accept="audio/*">
      <button class="btn" id="process-btn" disabled>Process with Version B</button>
    </div>
    <div class="status info" id="status">Waiting for file...</div>
    <div class="audio-controls">
      <div>
        <div><b>Original</b></div>
        <audio id="original-audio" controls></audio>
      </div>
      <div>
        <div><b>Version B</b></div>
        <audio id="processed-audio" controls></audio>
      </div>
    </div>
    <div class="log" id="log"></div>
  </div>
  <script type="module">
    import { SuperpoweredGlue, SuperpoweredWebAudio } from './node_modules/@superpoweredsdk/web/dist/Superpowered.js';
    let superpowered, pitchShifter, eq;
    let originalBuffer, sampleRate, processedBuffer;
    const log = msg => {
      const el = document.getElementById('log');
      el.innerHTML += `[${new Date().toLocaleTimeString()}] ${msg}<br>`;
      el.scrollTop = el.scrollHeight;
      console.log(msg);
    };
    const setStatus = (msg, type='info') => {
      const el = document.getElementById('status');
      el.textContent = msg;
      el.className = `status ${type}`;
    };
    // File input
    document.getElementById('audio-file').addEventListener('change', async e => {
      const file = e.target.files[0];
      if (!file) return;
      setStatus('Loading audio file...', 'info');
      log(`Selected file: ${file.name}`);
      // Decode audio
      const arrayBuffer = await file.arrayBuffer();
      const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
      const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
      sampleRate = audioBuffer.sampleRate;
      originalBuffer = audioBuffer;
      // Export to WAV for playback
      const wavBlob = bufferToWavBlob(audioBuffer);
      document.getElementById('original-audio').src = URL.createObjectURL(wavBlob);
      setStatus('File loaded. Ready to process.', 'success');
      document.getElementById('process-btn').disabled = false;
      log(`Audio loaded: ${audioBuffer.duration.toFixed(2)}s, ${audioBuffer.numberOfChannels}ch, ${audioBuffer.sampleRate}Hz`);
    });
    // Process button
    document.getElementById('process-btn').addEventListener('click', async () => {
      setStatus('Initializing Superpowered...', 'info');
      log('Initializing Superpowered...');
      document.getElementById('process-btn').disabled = true;
      // Init Superpowered
      if (!superpowered) {
        superpowered = await SuperpoweredGlue.Instantiate('ExampleLicenseKey-WillExpire-OnNextUpdate');
        log('Superpowered initialized.');
        // Log all available classes/keys for research
        log('Available Superpowered classes/keys:');
        const keys = Object.keys(superpowered);
        log(JSON.stringify(keys));
        // Log typeof and value for each key
        for (const k of keys) {
          let t = typeof superpowered[k];
          let v = superpowered[k];
          log(`[SDK] ${k}: typeof=${t} value=${t === 'function' ? v.toString().slice(0,60)+'...' : JSON.stringify(v).slice(0,60)+'...'}`);
        }
        // Log SuperpoweredWebAudio keys/types if available
        if (window.SuperpoweredWebAudio) {
          log('SuperpoweredWebAudio keys:');
          const waKeys = Object.keys(window.SuperpoweredWebAudio);
          log(JSON.stringify(waKeys));
          for (const k of waKeys) {
            let t = typeof window.SuperpoweredWebAudio[k];
            let v = window.SuperpoweredWebAudio[k];
            log(`[SuperpoweredWebAudio] ${k}: typeof=${t} value=${t === 'function' ? v.toString().slice(0,60)+'...' : JSON.stringify(v).slice(0,60)+'...'}`);
          }
        } else {
          log('SuperpoweredWebAudio is not available on window.');
        }
        // Log _functionsWithNamespace keys/types if available
        if (superpowered._functionsWithNamespace) {
          log('_functionsWithNamespace keys:');
          const fnKeys = Object.keys(superpowered._functionsWithNamespace);
          log(JSON.stringify(fnKeys));
          for (const k of fnKeys) {
            let t = typeof superpowered._functionsWithNamespace[k];
            let v = superpowered._functionsWithNamespace[k];
            log(`[_functionsWithNamespace] ${k}: typeof=${t} value=${t === 'function' ? v.toString().slice(0,60)+'...' : JSON.stringify(v).slice(0,60)+'...'}`);
          }
        } else {
          log('superpowered._functionsWithNamespace is not available.');
        }
      }
      // Prepare processing
      setStatus('Processing with Version B parameters...', 'info');
      log('Starting Version B processing...');
      let audioWorkletError = null;
      try {
        // AudioWorklet approach
        const numChannels = originalBuffer.numberOfChannels;
        const sampleRate = originalBuffer.sampleRate;
        const numFrames = originalBuffer.length;
        const duration = originalBuffer.duration;
        log(`[DEBUG] OfflineAudioContext: channels=${numChannels}, sampleRate=${sampleRate}, duration=${duration}`);
        let offlineCtx;
        try {
          offlineCtx = new OfflineAudioContext(numChannels, numFrames, sampleRate);
        } catch (err) {
          log('[ERROR] Failed to create OfflineAudioContext: ' + err.message);
          throw err;
        }
        let source;
        try {
          source = offlineCtx.createBufferSource();
          source.buffer = originalBuffer;
        } catch (err) {
          log('[ERROR] Failed to create buffer source: ' + err.message);
          throw err;
        }
        // Try loading the worklet
        try {
          log('[DEBUG] Loading Superpowered AudioWorklet...');
          if (window.SuperpoweredWebAudio && typeof window.SuperpoweredWebAudio.addAudioWorkletModule === 'function') {
            await window.SuperpoweredWebAudio.addAudioWorkletModule(offlineCtx, './node_modules/@superpoweredsdk/web/dist/SuperpoweredProcessor.js');
            log('[DEBUG] Superpowered AudioWorklet loaded.');
          } else {
            log('[ERROR] SuperpoweredWebAudio.addAudioWorkletModule is not available.');
            throw new Error('SuperpoweredWebAudio.addAudioWorkletModule is not available');
          }
        } catch (err) {
          log('[ERROR] Failed to load Superpowered AudioWorklet: ' + err.message);
          audioWorkletError = err;
          throw err;
        }
        // Try creating the processor node
        let processorNode;
        try {
          processorNode = new AudioWorkletNode(offlineCtx, 'SuperpoweredProcessor', {
            numberOfInputs: 1,
            numberOfOutputs: 1,
            outputChannelCount: [numChannels],
            processorOptions: {
              superpoweredOptions: {
                licenseKey: 'ExampleLicenseKey-WillExpire-OnNextUpdate',
                samplerate: sampleRate,
                pitchShiftCents: -50,
                formantCorrection: 0.95,
                eq: [
                  { frequency: 300, gain: 2, type: 'lowshelf' }
                ]
              }
            }
          });
          log('[DEBUG] SuperpoweredProcessor node created with Version B parameters.');
        } catch (err) {
          log('[ERROR] Failed to create SuperpoweredProcessor node: ' + err.message);
          audioWorkletError = err;
          throw err;
        }
        // Connect and render
        try {
          source.connect(processorNode).connect(offlineCtx.destination);
          log('[DEBUG] Starting offline rendering...');
          source.start();
          const renderedBuffer = await offlineCtx.startRendering();
          log('[DEBUG] Offline rendering complete.');
          const processedWav = bufferToWavBlob(renderedBuffer);
          document.getElementById('processed-audio').src = URL.createObjectURL(processedWav);
          setStatus('Processing complete! Listen and compare.', 'success');
          log('Processing complete. You can now compare the original and Version B.');
          document.getElementById('process-btn').disabled = false;
          return;
        } catch (err) {
          log('[ERROR] Offline rendering failed: ' + err.message);
          audioWorkletError = err;
          throw err;
        }
      } catch (err) {
        log('[ERROR] AudioWorklet approach failed: ' + (err.stack || err));
        // Try direct buffer processing if possible
        setStatus('AudioWorklet approach failed. Trying direct buffer processing...', 'warning');
        // Try to find a pitch shifting function in _functionsWithNamespace
        try {
          if (superpowered._functionsWithNamespace) {
            const fnKeys = Object.keys(superpowered._functionsWithNamespace);
            log('[DEBUG] _functionsWithNamespace keys: ' + JSON.stringify(fnKeys));
            // Try to find a pitch shifting or formant function
            const pitchFnKey = fnKeys.find(k => k.toLowerCase().includes('pitch') || k.toLowerCase().includes('formant'));
            if (pitchFnKey) {
              log(`[DEBUG] Found pitch/formant function: ${pitchFnKey}`);
              // Try to call it (this is a guess, as API is not documented)
              try {
                // Prepare input buffer (mono for simplicity)
                const input = originalBuffer.getChannelData(0);
                // Try to call the function with plausible arguments
                const out = new Float32Array(input.length);
                // This is a guess - actual signature may differ
                superpowered._functionsWithNamespace[pitchFnKey](input, out, input.length, sampleRate, -50, 0.95);
                log('[DEBUG] Direct pitch function call succeeded.');
                // Create AudioBuffer for playback
                const ctx = new (window.AudioContext || window.webkitAudioContext)();
                const outBuffer = ctx.createBuffer(1, out.length, sampleRate);
                outBuffer.copyToChannel(out, 0);
                const processedWav = bufferToWavBlob(outBuffer);
                document.getElementById('processed-audio').src = URL.createObjectURL(processedWav);
                setStatus('Direct pitch function processing complete! Listen and compare.', 'success');
                log('Direct pitch function processing complete. You can now compare the original and Version B.');
                document.getElementById('process-btn').disabled = false;
                return;
              } catch (err2) {
                log('[ERROR] Direct pitch function call failed: ' + err2.message);
                setStatus('Direct pitch function call failed: ' + err2.message, 'error');
              }
            } else {
              log('[ERROR] No pitch/formant function found in _functionsWithNamespace.');
              setStatus('No pitch/formant function found in _functionsWithNamespace.', 'error');
            }
          } else {
            log('[ERROR] _functionsWithNamespace is not available.');
            setStatus('_functionsWithNamespace is not available.', 'error');
          }
        } catch (err3) {
          log('[ERROR] Direct buffer processing failed: ' + err3.message);
          setStatus('Direct buffer processing failed: ' + err3.message, 'error');
        }
      }
      document.getElementById('process-btn').disabled = false;
    });
    // Helper: Convert AudioBuffer to WAV Blob
    function bufferToWavBlob(buffer) {
      const numChannels = buffer.numberOfChannels;
      const sampleRate = buffer.sampleRate;
      const length = buffer.length * numChannels * 2 + 44;
      const arrayBuffer = new ArrayBuffer(length);
      const view = new DataView(arrayBuffer);
      // RIFF header
      function writeString(view, offset, string) {
        for (let i = 0; i < string.length; i++) {
          view.setUint8(offset + i, string.charCodeAt(i));
        }
      }
      writeString(view, 0, 'RIFF');
      view.setUint32(4, 36 + buffer.length * numChannels * 2, true);
      writeString(view, 8, 'WAVE');
      writeString(view, 12, 'fmt ');
      view.setUint32(16, 16, true);
      view.setUint16(20, 1, true);
      view.setUint16(22, numChannels, true);
      view.setUint32(24, sampleRate, true);
      view.setUint32(28, sampleRate * numChannels * 2, true);
      view.setUint16(32, numChannels * 2, true);
      view.setUint16(34, 16, true);
      writeString(view, 36, 'data');
      view.setUint32(40, buffer.length * numChannels * 2, true);
      // PCM samples
      let offset = 44;
      for (let i = 0; i < buffer.length; i++) {
        for (let ch = 0; ch < numChannels; ch++) {
          let sample = buffer.getChannelData(ch)[i];
          sample = Math.max(-1, Math.min(1, sample));
          view.setInt16(offset, sample < 0 ? sample * 0x8000 : sample * 0x7FFF, true);
          offset += 2;
        }
      }
      return new Blob([arrayBuffer], { type: 'audio/wav' });
    }
  </script>
</body>
</html> 